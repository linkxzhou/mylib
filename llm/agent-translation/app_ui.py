import gradio as gr
import sys
sys.path.append('../llmapi')
from translation import TranslationAgent
from llmapi.llm_factory import LLMFactory, LLMChatAdapter
from llmapi.util.mylog import logger

class AppUI:
    def __init__(self):
        self.translator = None
        self.llm_chat_adapter = None
        
    def initialize_model(self, model_type, model_name, temperature, top_p):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            llm = LLMFactory.create(model_type, model_name=model_name, temperature=temperature, top_p=top_p)
            self.translator = TranslationAgent(llm)
            self.llm_chat_adapter = LLMChatAdapter(llm)
            return f"âœ… æ¨¡å‹ {model_type}/{model_name} åˆå§‹åŒ–æˆåŠŸ"
        except Exception as e:
            return f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}"
    
    def translate_text(self, source_lang, target_lang, source_text, country=""):
        """æ‰§è¡Œç¿»è¯‘"""
        if not self.translator:
            return "âŒ è¯·å…ˆåˆå§‹åŒ–æ¨¡å‹"
        if not source_text.strip():
            return "âŒ è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬"
        
        try:
            return self.translator.translate(source_lang, target_lang, source_text, country, self.llm_chat_adapter)
        except Exception as e:
            logger.error(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
            return f"âŒ ç¿»è¯‘å¤±è´¥: {str(e)}"
    
    def chat_with_agent(self, message, history):
        """ä¸æ™ºèƒ½ä½“å¯¹è¯"""
        if not self.llm_chat_adapter:
            return history, ""
        
        try:
            # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
            conversation = ""
            for msg in history:
                if msg["role"] == "user":
                    conversation += f"ç”¨æˆ·: {msg['content']}\n"
                elif msg["role"] == "assistant":
                    conversation += f"åŠ©æ‰‹: {msg['content']}\n"
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            conversation += f"ç”¨æˆ·: {message}\nåŠ©æ‰‹: "
            
            # è·å–å›å¤ - LLMChatAdapter.chat è¿”å› (bool, str) å…ƒç»„
            success, response = self.llm_chat_adapter.chat(conversation)
            
            if not success:
                response = f"å¯¹è¯å¤±è´¥: {response}"
            
            # æ›´æ–°å†å²è®°å½•
            history.append({"role": "user", "content": message})
            history.append({"role": "assistant", "content": response})
            
            return history, ""
        except Exception as e:
            error_msg = f"å¯¹è¯å¤±è´¥: {str(e)}"
            history.append({"role": "user", "content": message})
            history.append({"role": "assistant", "content": error_msg})
            return history, ""
    
    def create_interface(self):
        """åˆ›å»º Gradio ç•Œé¢"""
        with gr.Blocks(title="AI ç¿»è¯‘åŠ©æ‰‹") as demo:
            gr.Markdown("# ğŸ¤– AI ç¿»è¯‘åŠ©æ‰‹")
            
            # æ¨¡å‹é…ç½®
            with gr.Row():
                model_type = gr.Dropdown(
                    choices=["qianfan", "openai", "qwen", "zhipu", "ollama", "siliconflow"],
                    value="qianfan", label="æ¨¡å‹ç±»å‹"
                )
                model_name = gr.Textbox(value="deepseek-v3", label="æ¨¡å‹åç§°")
                temperature = gr.Slider(0.0, 2.0, 0.6, step=0.1, label="Temperature")
                top_p = gr.Slider(0.0, 1.0, 0.9, step=0.05, label="Top-p")
            
            init_btn = gr.Button("åˆå§‹åŒ–æ¨¡å‹", variant="primary")
            init_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
            
            init_btn.click(self.initialize_model, [model_type, model_name, temperature, top_p], init_status)
            
            with gr.Tab("å¯¹è¯"):
                chatbot = gr.Chatbot(height=400, type="messages")
                msg = gr.Textbox(label="æ¶ˆæ¯", placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")
                with gr.Row():
                    send_btn = gr.Button("å‘é€", variant="primary")
                    clear_btn = gr.Button("æ¸…ç©º")
                
                send_btn.click(self.chat_with_agent, [msg, chatbot], [chatbot, msg])
                msg.submit(self.chat_with_agent, [msg, chatbot], [chatbot, msg])
                clear_btn.click(
                    fn=lambda: ([], ""), 
                    inputs=[], 
                    outputs=[chatbot, msg]
                )
            
            with gr.Tab("ç¿»è¯‘"):
                with gr.Row():
                    source_lang = gr.Dropdown(
                        choices=["English", "Chinese", "Japanese", "Korean", "French", "German", "Spanish", "Russian"],
                        value="English", label="æºè¯­è¨€"
                    )
                    target_lang = gr.Dropdown(
                        choices=["Chinese", "English", "Japanese", "Korean", "French", "German", "Spanish", "Russian"],
                        value="Chinese", label="ç›®æ ‡è¯­è¨€"
                    )
                    country = gr.Textbox(label="åœ°åŒº (å¯é€‰)", placeholder="ä¾‹å¦‚: Taiwan")
                
                with gr.Row():
                    source_text = gr.Textbox(label="å¾…ç¿»è¯‘æ–‡æœ¬", lines=6, placeholder="è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬...")
                    translation_result = gr.Textbox(label="ç¿»è¯‘ç»“æœ", lines=6, interactive=False)
                
                translate_btn = gr.Button("å¼€å§‹ç¿»è¯‘", variant="primary")
                translate_btn.click(self.translate_text, [source_lang, target_lang, source_text, country], translation_result)
        
        return demo

def main():
    try:
        ui = AppUI()
        demo = ui.create_interface()
        demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
    except Exception as e:
        logger.error(f"åº”ç”¨å¯åŠ¨å¤±è´¥: {str(e)}")
        print(f"âŒ åº”ç”¨å¯åŠ¨å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()